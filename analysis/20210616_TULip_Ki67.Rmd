---
title: "TULip Ki67 Study"
author: |
  | Stephen Pederson
  | Dame Roma Mitchell Cancer Research Laboratories
  | Adelaide Medical School
  | University of Adelaide
date: "`r format(Sys.Date(), '%d %B, %Y')`"
output: workflowr::wflow_html
editor_options:
  chunk_output_type: console
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(
    echo = TRUE,
    message = FALSE,
    warning = FALSE
)
```

```{r packages}
library(tidyverse)
library(readxl)
library(scales)
library(glue)
library(magrittr)
library(pander)
library(cowplot)
library(matrixStats)
library(zoo)
library(truncnorm)
library(parallel)
```

```{r options}
theme_set(theme_bw())
geom_mean <- function(x, ...){
  exp(mean(log(x), ...))
}
```

# Introduction

The common measurement of Ki67 data is as a percentage of cells staining +ve for Ki67.

## Power Calculations

In this study a comparison of an Aromatase Inhibitor treated arm (Letrazole) with a double-treated arm (Letrazole + Testosterone Undecanoate).
The desired reduction in Ki67 for double-treated (L+TU) samples is an additional 20% beyond that seen by Letrazole alone.

Based on the values observed in [*Long-term outcome and prognostic value of Ki67 after perioperative endocrine therapy in postmenopausal women with hormone-sensitive early breast cancer (POETIC): an open-label, multicentre, parallel-group, randomised, phase 3 trial* (The Lancet, 2020)](https://www.thelancet.com/journals/lanonc/article/PIIS1470-2045(20)30458-7/fulltext), untreated samples were simulated using a truncated normal distribution with location &mu; = 0.086 and scale &sigma; = 0.18.
Truncation points were the values 0 & 1, and this gave distributions which provided broadly similar values for median and the IQR as obtained by this study.

Whilst a non-responder rate to both compounds was simulated between 10% to 30%, it may of note that in [one early study](https://cancerres.aacrjournals.org/content/63/19/6523.long) up to 25% of patients failed to respond to Letrazole.
Given the significant advances since 2003, the non-responder range as used here was considered suitable.
However, it should be noted that as part of the simulation process some non-responders may appear to be responders just by having low Ki67 values prior to intervention.
This is relatively representative of the true data where some non-responders will not be able to be identified unless matched Ki67 values are obtained pre/post intervention.


```{r sim_data}
sim_data <- function(n0, n1, ki0 = 0.065, sigma0 = 0.19, delta1 = 0.923, delta2 = 0.997, p_non = 0.1, dropout = 0.05, ...){
  
  ## Here n0 represents the letrazole arm, whilst n1 represents the combined arm
  ## The pre-treatment data is designed to replicate the POETIC data, with 
  ## reductions in either arm including a non-responder rate. Location and 
  ## scale parameters are designed to reduce in accordance with the desired 
  ## reduction
  a1 <- 1-delta1
  a2 <- 1-delta2
  
  ## Simulate initial values
  pre <- rtruncnorm(n0, a = 0, b = 1, mean = ki0, sd = sigma0)
  let <- rtruncnorm(n0, a = 0, b = 1, mean = ki0*a1, sd = sigma0*sqrt(a1))
  ltu <- rtruncnorm(n1, a = 0, b = 1, mean = ki0*a2, sd = sigma0*sqrt(a2))
  
  ## Add non-responders & resample
  non <- as.logical(rbinom(n0, 1, p_non))
  let[non] <- rtruncnorm(sum(non), a = 0, b = 1, mean = ki0, sd = sigma0)
  non <- as.logical(rbinom(n1, 1, p_non))
  ltu[non] <- rtruncnorm(sum(non), a = 0, b = 1, mean = ki0, sd = sigma0)
  
  ## Add dropouts
  d1 <- as.logical(rbinom(n0, 1, dropout))
  d2 <- as.logical(rbinom(n1, 1, dropout))
  let <- let[!d1]
  ltu <- ltu[!d2]

  list(pre = pre, let = let, ltu = ltu)
}
```

```{r default_params}
ki0 <- 0.065
sigma0 <- 0.19
delta1 <- 0.923
delta2 <- 0.997
const <- function(mu, sigma, a, b){
  alpha <- (a - mu)/sigma
  beta <- (b - mu)/sigma
  qnorm(0.5*(pnorm(alpha) + pnorm(beta)))
}
expected <- list(
 Pre = ki0 + const(ki0, sigma0, 0, 1)*sigma0, 
 Let = (1-delta1)*ki0 + const((1-delta1)*ki0, sqrt(1-delta1)*sigma0, 0, 1)*sqrt(1 - delta1)*sigma0, 
 `L+TU` = (1-delta2)*ki0 + const((1-delta2)*ki0, sqrt(1-delta2)*sigma0, 0, 1)*sqrt(1 - delta2)*sigma0
)
```

```{r tab_expected}
expected %>%
  as_tibble() %>%
  pivot_longer(
    cols = everything(),
    names_to = "Treatment",
    values_to = "Ki67"
  ) %>%
  mutate(
    `Expected Reduction` = percent(1 - Ki67 / dplyr::filter(., Treatment == "Pre")$Ki67, accuracy = 0.1),
    Ki67 = percent(Ki67, accuracy = 0.1)
  ) %>%
  pander(
    justify = "lrr",
    caption = "
    Expected median Ki67% and the expected reduction in Ki67% using the default simulation parameters.
    Values were set to show a slight overestimate of change, given that a proportion of non-responders were to be included in the simulations
    "
  )
```



```{r example_data}
set.seed(123)
example_data <- sim_data(
  n0 = 1000, n1 =1000, 
  ki0 = 0.065, sigma0 = 0.19, 
  delta1 = 0.923, delta2 = 0.997
) %>%
  lapply(list) %>%
  as_tibble()
```

```{r example_boxplot, fig.width=10, fig.height=8, fig.cap = "Boxplot of example simulated data showing the strong recapitulation of the observed Ki67% distributions from the POETIC study."}
example_data %>%
  pivot_longer(
    cols = everything(),
    names_to = "treatment",
    values_to = "Ki67"
  ) %>%
  unnest(Ki67) %>%
  mutate(
    treatment = c(pre = "Pre", let = "Let", ltu = "L+TU")[treatment],
    treatment = factor(treatment, levels = c("Pre", "Let", "L+TU"))
  ) %>%
  ggplot(aes(treatment, Ki67)) +
  geom_boxplot() +
  scale_y_continuous(labels = scales::percent) +
  labs(
    x = "Treatment",
    y = "Ki67 %"
  )
```

```{r example_table}
example_data %>%
  pivot_longer(
    cols = everything(),
    names_to = "treatment",
    values_to = "Ki67"
  ) %>%
  unnest(Ki67) %>%
  mutate(
    treatment = c(pre = "Pre", let = "Let", ltu = "L+TU")[treatment],
    treatment = factor(treatment, levels = c("Pre", "Let", "L+TU"))
  ) %>%
  group_by(treatment) %>%
  summarise(
    Median = median(Ki67),
    IQR = glue("[{percent(quantile(Ki67, 0.25), accuracy = 0.1)}, {percent(quantile(Ki67, 0.75), accuracy = 0.1)}]")
  ) %>%
  mutate(
    Reduction = 1 - Median / dplyr::filter(., treatment == "Pre")$Median,
    Reduction = percent(Reduction, accuracy = 0.1),
    Median = percent(Median, accuracy = 0.1)
  ) %>%
  rename(Treatment = treatment) %>%
  pander(
    caption = "
    Example simulated data showing an approximate recapitulation of the untreated samples in the POETIC study, along with reductions in the median Ki67% of 75% and 95%.
    The 75% reduction simulated for Letrazole again recapitulates the POETIC dataset well where this reduction was also observed.
    "
  )
```


```{r sim_params}
n_sim <- 5000
alpha <- 0.025
N <- seq(60, 120, by = 10)
n0 <- floor(c(N/2, N/2.5, N/3))
n1 <- rep(N, 3) - n0
```

```{r sim_res}
set.seed(1000)
sim_res <- list(
  tibble(
    n0 = n0,
    n1 = n1,
    p_non = 0.1
  ),
  tibble(
    n0 = n0,
    n1 = n1,
    p_non = 0.20
  ),
  tibble(
    n0 = n0,
    n1 = n1,
    p_non = 0.30
  )
) %>%
  bind_rows() %>%
  split(f = seq_len(nrow(.))) %>%
  mclapply(
    function(x){
      data <- replicate(
        n_sim,
        {
          sim_data(n0 = x$n0, n1 = x$n1, p_non = x$p_non)
        }
      )
      p <- apply(
        data, 
        MARGIN = 2, 
        function(x){wilcox.test(x$let, x$ltu)$p.value}
      )
      median_pre <- apply(data, MARGIN = 2, function(x){median(x$pre)})
      median_let <- apply(data, MARGIN = 2, function(x){median(x$let)})
      median_ltu <- apply(data, MARGIN = 2, function(x){median(x$ltu)})
      mutate(
        x, 
        power = mean(p < alpha),
        median_pre = median(median_pre),
        median_let = median(median_let),
        median_ltu = median(median_ltu)
        )
    },
    mc.cores = 6
  ) %>%
  bind_rows() %>%
  mutate(
    N = n0 + n1
  ) 
```

```{r plot_curves, fig.height=8, fig.width=10, fig.cap = "*Power curves for detection of an additional 20% reduction in Ki67 due to a combination treatment of L+TU in comparison to Letrazole alone. Panels represent equal samples sizes in both treatment groups (n~L+TU~=n~L~), having an extra 50% of participants in the combination group (n~L+TU~ = 1.5n~L~), or having double the number of particiapnts in the combined treatment group (n~L+TU~ = 2n~L~). Error bars indicate a 95% confidence interval around the power estimates. A dropout rate of 5% has been incorporated into the simulations.*"}
sim_res %>% 
  mutate(
    `n1/n0` = paste0("n[L+TU] == ",round(n1/n0, 1), "%*%n[L]") %>%
      str_remove_all("1%\\*%") %>%
      str_replace_all("2\\.", "2%*%") %>%
      fct_inorder(),
    se = sqrt(power*(1-power)/n_sim)
  ) %>% 
  ggplot(aes(N, power, colour = as.factor(p_non))) +
  geom_point() + 
  geom_line() +
  geom_errorbar(
    aes(ymin = power - 1.96*se, ymax = power + 1.96*se),
    width = 2
  ) +
  facet_wrap(~`n1/n0`, labeller = label_parsed) +
  # scale_x_continuous(breaks = seq(40, 200, by = 40)) +
  scale_y_continuous(labels = scales::percent) +
  labs(
    x = "Total Sample Size",
    y = "Power",
    colour = "% Non-Responders"
  ) +
  theme(
    legend.position = c(0.9, 0.1)
  )
```

## Conclusion

Using 30% non-responders from the above power curves:

- *Keeping group sizes equal* requires N = 100 (n1 = 60; n2 = 60) to achieve a 90% power (in the presence of 30% non-responders)
- *Including an additional 50% of participants in the combined treatment group* is able to achieve a power > 90% at N = 100 (n1 = 40; n2 = 60)
- *Including double the number of participants in the combined treatment group* is able to achieve a power of 90% at N > 100 (n1 = 35; n2 = 70)

Importantly a *sample size of 100 participants* exceeds a power of 80% for all combinations of n~L+TU~ and n~L~ and all non-response rates.
Allowing for drop-outs, a recommended total sample size for the study should be 100-110 participants.
